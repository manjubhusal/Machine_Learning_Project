{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324c86d9c88e2ea8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "021f8460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T22:01:22.187102100Z",
     "start_time": "2024-02-10T22:01:22.152067100Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4549131f",
   "metadata": {},
   "source": [
    "# Load, Prepare and Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead142e5524db46",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5626f04e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T22:01:23.053492700Z",
     "start_time": "2024-02-10T22:01:22.192106800Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df_len = len(df)\n",
    "#df.head()\n",
    "\n",
    "# Handling missing / incorrect data\n",
    "# There is no missing or incorrect data, so this will remain empty for now\n",
    "#df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e7acc2936e9b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9383ad70215add3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T22:01:23.292788100Z",
     "start_time": "2024-02-10T22:01:23.056495400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>...</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>C11</th>\n",
       "      <th>C12</th>\n",
       "      <th>C13</th>\n",
       "      <th>C14</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>316109</th>\n",
       "      <td>316110</td>\n",
       "      <td>H</td>\n",
       "      <td>10770</td>\n",
       "      <td>264.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>191.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163437</th>\n",
       "      <td>163438</td>\n",
       "      <td>R</td>\n",
       "      <td>6019</td>\n",
       "      <td>583.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>264.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210807</th>\n",
       "      <td>210808</td>\n",
       "      <td>W</td>\n",
       "      <td>7078</td>\n",
       "      <td>479.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>315.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9318</th>\n",
       "      <td>9319</td>\n",
       "      <td>W</td>\n",
       "      <td>17162</td>\n",
       "      <td>555.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>315.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343112</th>\n",
       "      <td>343113</td>\n",
       "      <td>C</td>\n",
       "      <td>7099</td>\n",
       "      <td>545.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>195.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID ProductCD  card1  card2  card3 card4  card5   card6   \n",
       "316109         316110         H  10770  264.0  150.0  visa  226.0  credit  \\\n",
       "163437         163438         R   6019  583.0  150.0  visa  226.0  credit   \n",
       "210807         210808         W   7078  479.0  150.0  visa  226.0   debit   \n",
       "9318             9319         W  17162  555.0  150.0  visa  226.0   debit   \n",
       "343112         343113         C   7099  545.0  185.0  visa  195.0  credit   \n",
       "\n",
       "           addr1     addr2  ...   C6   C7   C8   C9   C10  C11  C12   C13   \n",
       "316109     191.0      87.0  ...  1.0  0.0  1.0  0.0   1.0  1.0  0.0   1.0  \\\n",
       "163437     264.0      87.0  ...  1.0  0.0  1.0  0.0   1.0  1.0  0.0   1.0   \n",
       "210807     315.0      87.0  ...  4.0  0.0  0.0  2.0   0.0  1.0  0.0  34.0   \n",
       "9318       315.0      87.0  ...  1.0  0.0  0.0  1.0   0.0  1.0  0.0   1.0   \n",
       "343112  NotFound  NotFound  ...  4.0  4.0  9.0  0.0  20.0  6.0  6.0  19.0   \n",
       "\n",
       "        C14  isFraud  \n",
       "316109  1.0        0  \n",
       "163437  1.0        0  \n",
       "210807  1.0        0  \n",
       "9318    1.0        0  \n",
       "343112  3.0        0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data, testing_data = train_test_split(df, test_size=0.20, random_state=100, shuffle=True)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07ec79a2971185",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Is our data pure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25b2e35f6e48859",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T22:01:23.298296900Z",
     "start_time": "2024-02-10T22:01:23.292788100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_purity(data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if len(unique_classes) == 2:\n",
    "        return True\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed3ddc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_purity(training_data[training_data.card1 < 200].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74893ed4ab0312be",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83766a156f7419c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T22:01:23.304844200Z",
     "start_time": "2024-02-10T22:01:23.298296900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify_data(data):\n",
    "\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4008f0b62d30be",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Potential Splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b76d8354e830e8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T22:01:23.310084Z",
     "start_time": "2024-02-10T22:01:23.302842200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range(n_columns - 1):          # excluding the last column which is the label\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        type_of_feature = FEATURE_TYPES[column_index]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            potential_splits[column_index] = []\n",
    "            for index in range(len(unique_values)):\n",
    "                if index != 0:\n",
    "                    current_value = unique_values[index]\n",
    "                    previous_value = unique_values[index - 1]\n",
    "                    potential_split = (current_value + previous_value) / 2\n",
    "\n",
    "                    potential_splits[column_index].append(potential_split)\n",
    "        \n",
    "        # feature is categorical\n",
    "        # (there need to be at least 2 unique values, otherwise in the\n",
    "        # split_data function data_below would contain all data points\n",
    "        # and data_above would be empty)\n",
    "        elif len(unique_values) > 1:\n",
    "            potential_splits[column_index] = unique_values\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b00e5eeccb7530",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Split Data [?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0b56eb94beef16b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T22:01:23.315089100Z",
     "start_time": "2024-02-10T22:01:23.310084Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_data(data, split_column, split_value):\n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_below = data[split_column_values <= split_value]\n",
    "        data_above = data[split_column_values >  split_value]\n",
    "    \n",
    "    # feature is categorical   \n",
    "    else:\n",
    "        data_below = data[split_column_values == split_value]\n",
    "        data_above = data[split_column_values != split_value]\n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c516fbd9aa0737de",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Lowest Overall Entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d863d7688f8c40cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T22:01:23.331883900Z",
     "start_time": "2024-02-10T22:01:23.317091200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "     \n",
    "    return entropy\n",
    "def calculate_overall_entropy(data_below, data_above):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_entropy =  (p_data_below * calculate_entropy(data_below) \n",
    "                      + p_data_above * calculate_entropy(data_above))\n",
    "    \n",
    "    return overall_entropy\n",
    "def determine_best_split(data, potential_splits):\n",
    "    \n",
    "    overall_entropy = 9999\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9400241b833643b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "364330afde866f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T22:01:23.331883900Z",
     "start_time": "2024-02-10T22:01:23.322168700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_tree = {\"question\": [\"yes_answer\", \n",
    "                         \"no_answer\"]}\n",
    "example_tree = {\"petal_width <= 0.8\": [\"Iris-setosa\", \n",
    "                                      {\"petal_width <= 1.65\": [{\"petal_length <= 4.9\": [\"Iris-versicolor\", \n",
    "                                                                                        \"Iris-virginica\"]}, \n",
    "                                                                \"Iris-virginica\"]}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc4d204c7aee959f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T22:01:23.332884900Z",
     "start_time": "2024-02-10T22:01:23.327030900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    \n",
    "    feature_types = []\n",
    "    n_unique_values_threshold = 15\n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_threshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "    \n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e2b36e7009a072c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T22:01:23.342185Z",
     "start_time": "2024-02-10T22:01:23.334886100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, counter=0, min_samples=2, max_depth=5):\n",
    "    \n",
    "    # data preparations\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(df)\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df           \n",
    "    \n",
    "    \n",
    "    # base cases\n",
    "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        classification = classify_data(data)\n",
    "        \n",
    "        return classification\n",
    "\n",
    "    \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1\n",
    "\n",
    "        # helper functions \n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        # determine question\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            question = \"{} <= {}\".format(feature_name, split_value)\n",
    "            \n",
    "        # feature is categorical\n",
    "        else:\n",
    "            question = \"{} = {}\".format(feature_name, split_value)\n",
    "        \n",
    "        # instantiate sub-tree\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        # find answers (recursion)\n",
    "        yes_answer = decision_tree_algorithm(data_below, counter, min_samples, max_depth)\n",
    "        no_answer = decision_tree_algorithm(data_above, counter, min_samples, max_depth)\n",
    "        \n",
    "        # If the answers are the same, then there is no point in asking the qestion.\n",
    "        # This could happen when the data is classified even though it is not pure\n",
    "        # yet (min_samples or max_depth base case).\n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb268e7504501657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T22:01:24.192676600Z",
     "start_time": "2024-02-10T22:01:23.339181100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "tree = decision_tree_algorithm(training_data, max_depth=5)\n",
    "pprint(tree, width=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181605841fef9414",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T22:01:24.192676600Z",
     "start_time": "2024-02-10T22:01:24.188958900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
